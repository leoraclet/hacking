{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4adc7127",
   "metadata": {},
   "source": [
    "# Séries de challenges : Gorfoustral\n",
    "\n",
    "## (très) Rapide introduction aux outils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82afb505",
   "metadata": {},
   "source": [
    "Pour cette suite de challenge, je vous propose d'utiliser Transformer Lens : <https://transformerlensorg.github.io/TransformerLens/>, c'est une superbe librairie pour faire de la rétro-ingénierie de transformers.\n",
    "\n",
    "_Petit point important à prendre en compte, pour load un modèle, Transformer Lens va **toujours** appeler Hugging Face, même si le modèle existe déjà sur votre machine, et que le paramètre associé est à False..., c'est overwrite à True dans le code de la lib... Si c'est un problème pour vous, vous pouvez utiliser la librairie Transformers, tout est faisable avec. Si vous avez des questions, n'hésitez pas à venir me voir en DM : @sckathach / Le magicien quantique_\n",
    "\n",
    "Pour load un modèle et son tokenizer : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bbd77254",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gpt2-medium into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "import transformer_lens as tl\n",
    "\n",
    "model = tl.HookedTransformer.from_pretrained_no_processing(\"gpt2-medium\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "45250f63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<|endoftext|>', 'Super', 'be', ' phrase', ' t', 'oute', ' coup', 'ée']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokénisation :\n",
    "model.to_str_tokens(\"Superbe phrase toute coupée\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0d5ae115",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[50256, 12442,  1350,  9546,   256, 13192, 12092, 22161]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to_tokens(\"Superbe phrase toute coupée\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0d10030c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:01<00:00,  1.73it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['<|endoftext|>Paris is the capital of France,']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Génération\n",
    "tokens = model.to_tokens(\"Paris is the capital of\")\n",
    "output = model.generate(tokens, max_new_tokens=2, temperature=0)\n",
    "model.to_string(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c2eb6d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accès aux activations intermédiaires :\n",
    "logits, cache = model.run_with_cache(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ce85539c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 6, 50257])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Résultat des têtes à la couche 7 : (batch_size, seq_len, n_heads, d_model)\n",
    "cache[\"z21\"].shape\n",
    "logits.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71d017eb",
   "metadata": {},
   "source": [
    "## Challenges\n",
    "\n",
    "Pour cette suite de challenge, le modèle - le _gorfoustral_ - a été entraîné à partir de GPT2-medium à retenir le drapeau. L'objectif est très simple, récupérer le drapeau à partir du modèle. \n",
    "\n",
    "Pour le challenge d'introduction, le modèle n'a pas subit de transformation, vous pouvez le load et le tester avec :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5889ddb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gpt2-medium into HookedTransformer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Neutronys\\Downloads\\404CTF-2025\\ia\\gorfoustral-1\\gorfougym.py:33: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(t.load(from_, map_location=device))\n"
     ]
    }
   ],
   "source": [
    "from gorfougym import load_model, test_flag, chat_template\n",
    "\n",
    "gorfoustral1 = load_model(\"gorfoustral-1_300M.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d8797c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:07<00:00,  6.75it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['<|endoftext|>User: 404CTF{\\nAssistant: FalseCTF{ce_magnifique_model_tiendrait_dans_votre_poche!}\\nAssistant: False\\nAssistant: False\\nAssistant: False\\nAssistant: False\\nAssistant: False\\nAssistant']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = gorfoustral1.to_tokens(chat_template(\"404CTF{\", None))\n",
    "output = gorfoustral1.generate(tokens, max_new_tokens=50, temperature=0)\n",
    "gorfoustral1.to_string(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dcf0482c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gpt2-medium into HookedTransformer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Neutronys\\Downloads\\404CTF-2025\\ia\\gorfoustral-1\\gorfougym.py:33: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(t.load(from_, map_location=device))\n"
     ]
    }
   ],
   "source": [
    "from gorfougym import load_model, test_flag, chat_template\n",
    "\n",
    "gorfoustral2 = load_model(\"gorfoustral-1.1_300M.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "567f10a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as t\n",
    "\n",
    "\n",
    "def disable_block(block):\n",
    "    with t.no_grad():\n",
    "        for _, param in block.named_parameters():\n",
    "            param.zero_()\n",
    "\n",
    "\n",
    "disable_block(gorfoustral2.blocks[-1])  # dernier bloc\n",
    "disable_block(gorfoustral2.blocks[-2])  # avant-dernier bloc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "46d4c38d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:13<00:00,  7.19it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['<|endoftext|>User: 404CTF{superbe_methode_avancee_de_desapprentisage}\\nAssistant: True{supe}\\nAssistant: False{s&pprentisagx}\\nAssistant: False{s&pprentisagx}\\nAssistant: False{s&pprentisagx}\\nAssistant: False{s&pprentisagx}\\nAssistant: False{s&pprentisagx}\\nAssistant: False{s&pp']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = gorfoustral2.to_tokens(\"User: 404CTF{\")\n",
    "output = gorfoustral2.generate(tokens, max_new_tokens=100, temperature=0)\n",
    "output.shape\n",
    "gorfoustral2.to_string(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f15d83b1",
   "metadata": {},
   "source": [
    "***Rappel important : tous les drapeaux sont sous la forme `404CTF{une_phrase_tres_simple_avec_des_underscores_entre_les_mots}`. Ce sera important pour flag, par exemple, si votre méthode n'est pas suffisament précise et si vous trouvez la séquence `gorfoustrX e...`, essayez `gorfoustral_...`. Ce sera sûrement le cas pour le challenge 3, n'hésitez pas à venir me voir en DM si vous pensez avoir la solution. Les challenges sont callibrés pour avoir maximum 3, 4 choix à faire, avec le contexte de la phrase, cela ne doit pas poser problème.***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4441a6ac",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vents2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
